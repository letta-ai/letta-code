[
  {
    "id": "sonnet-4.5",
    "handle": "anthropic/claude-sonnet-4-5-20250929",
    "label": "Claude Sonnet 4.5 (default)",
    "description": "The recommended default model (currently Sonnet 4.5)",
    "isDefault": true,
    "isFeatured": true,
    "updateArgs": {
      "context_window": 180000,
      "max_output_tokens": 64000,
      "max_reasoning_tokens": 31999
    }
  },
  {
    "id": "sonnet-4.5-no-reasoning",
    "handle": "anthropic/claude-sonnet-4-5-20250929",
    "label": "Claude Sonnet 4.5 (no reasoning)",
    "description": "Sonnet 4.5 with extended thinking/reasoning explicitly disabled",
    "updateArgs": {
      "enable_reasoner": false,
      "context_window": 180000,
      "max_output_tokens": 64000
    }
  },
  {
    "id": "opus",
    "handle": "anthropic/claude-opus-4-5-20251101",
    "label": "Claude Opus 4.5",
    "description": "Anthropic's newest flagship Opus 4.5 model",
    "isFeatured": true,
    "updateArgs": {
      "context_window": 180000,
      "max_output_tokens": 64000,
      "max_reasoning_tokens": 31999
    }
  },
  {
    "id": "opus-4.1",
    "handle": "anthropic/claude-opus-4-1-20250805",
    "label": "Claude Opus 4.1",
    "description": "Anthropic's previous version of Opus",
    "updateArgs": {
      "context_window": 180000,
      "max_output_tokens": 64000,
      "max_reasoning_tokens": 31999
    }
  },
  {
    "id": "haiku",
    "handle": "anthropic/claude-haiku-4-5-20251001",
    "label": "Claude Haiku 4.5",
    "description": "Anthropic's fastest model",
    "isFeatured": true,
    "updateArgs": {
      "context_window": 180000,
      "max_output_tokens": 64000
    }
  },
  {
    "id": "gpt-5-codex",
    "handle": "openai/gpt-5-codex",
    "label": "GPT-5-Codex",
    "description": "A variant of GPT-5 optimized for agentic coding",
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.2-none",
    "handle": "openai/gpt-5.2",
    "label": "GPT-5.2 (none)",
    "description": "OpenAI's latest model (no reasoning, fastest GPT-5.2 option)",
    "updateArgs": {
      "reasoning_effort": "none",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.2-low",
    "handle": "openai/gpt-5.2",
    "label": "GPT-5.2 (low)",
    "description": "OpenAI's latest model (some reasoning enabled)",
    "updateArgs": {
      "reasoning_effort": "low",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.2-medium",
    "handle": "openai/gpt-5.2",
    "label": "GPT-5.2 (medium)",
    "description": "OpenAI's latest model (using their recommended reasoning level)",
    "isFeatured": true,
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.2-high",
    "handle": "openai/gpt-5.2",
    "label": "GPT-5.2 (high)",
    "description": "OpenAI's latest model (high reasoning effort)",
    "updateArgs": {
      "reasoning_effort": "high",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.2-xhigh",
    "handle": "openai/gpt-5.2",
    "label": "GPT-5.2 (extra-high)",
    "description": "OpenAI's latest model (maximum reasoning depth)",
    "updateArgs": {
      "reasoning_effort": "xhigh",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-none",
    "handle": "openai/gpt-5.1",
    "label": "GPT-5.1 (none)",
    "description": "OpenAI's GPT-5.1 model (no reasoning, fastest GPT-5.1 option)",
    "updateArgs": {
      "reasoning_effort": "none",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-low",
    "handle": "openai/gpt-5.1",
    "label": "GPT-5.1 (low)",
    "description": "OpenAI's GPT-5.1 model (some reasoning enabled)",
    "updateArgs": {
      "reasoning_effort": "low",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-medium",
    "handle": "openai/gpt-5.1",
    "label": "GPT-5.1 (medium)",
    "description": "OpenAI's GPT-5.1 model (using their recommended reasoning level)",
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-high",
    "handle": "openai/gpt-5.1",
    "label": "GPT-5.1 (high)",
    "description": "OpenAI's GPT-5.1 model (maximum reasoning depth)",
    "updateArgs": {
      "reasoning_effort": "high",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-codex-none",
    "handle": "openai/gpt-5.1-codex",
    "label": "GPT-5.1-Codex (none)",
    "description": "GPT-5.1-Codex with no reasoning (fastest Codex option)",
    "updateArgs": {
      "reasoning_effort": "none",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-codex-medium",
    "handle": "openai/gpt-5.1-codex",
    "label": "GPT-5.1-Codex (medium)",
    "description": "GPT-5.1-Codex with recommended reasoning level",
    "isFeatured": true,
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-codex-high",
    "handle": "openai/gpt-5.1-codex",
    "label": "GPT-5.1-Codex (high)",
    "description": "GPT-5.1-Codex with maximum reasoning depth",
    "updateArgs": {
      "reasoning_effort": "high",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-codex-max-medium",
    "handle": "openai/gpt-5.1-codex-max",
    "label": "GPT-5.1-Codex (max-medium)",
    "description": "GPT-5.1-Codex with maximum capabilities enabled",
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-codex-max-high",
    "handle": "openai/gpt-5.1-codex-max",
    "label": "GPT-5.1-Codex (max-high)",
    "description": "GPT-5.1-Codex with maximum capabilities enabled",
    "updateArgs": {
      "reasoning_effort": "high",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5.1-codex-max-x-high",
    "handle": "openai/gpt-5.1-codex-max",
    "label": "GPT-5.1-Codex (max-x-high)",
    "description": "GPT-5.1-Codex with maximum capabilities enabled",
    "updateArgs": {
      "reasoning_effort": "xhigh",
      "verbosity": "medium",
      "context_window": 272000,
      "max_output_tokens": 128000
    }
  },
  {
    "id": "gpt-5-minimal",
    "handle": "openai/gpt-5",
    "label": "GPT-5 (minimal)",
    "description": "OpenAI's latest model (limited reasoning, fastest GPT-5 option)",
    "updateArgs": {
      "reasoning_effort": "minimal",
      "verbosity": "medium",
      "context_window": 272000
    }
  },
  {
    "id": "gpt-5-low",
    "handle": "openai/gpt-5",
    "label": "GPT-5 (low)",
    "description": "OpenAI's latest model (some reasoning enabled)",
    "updateArgs": {
      "reasoning_effort": "low",
      "verbosity": "medium",
      "context_window": 272000
    }
  },
  {
    "id": "gpt-5-medium",
    "handle": "openai/gpt-5",
    "label": "GPT-5 (medium)",
    "description": "OpenAI's latest model (using their recommended reasoning level)",
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000
    }
  },
  {
    "id": "gpt-5-high",
    "handle": "openai/gpt-5",
    "label": "GPT-5 (high)",
    "description": "OpenAI's latest model (maximum reasoning depth)",
    "updateArgs": {
      "reasoning_effort": "high",
      "verbosity": "medium",
      "context_window": 272000
    }
  },
  {
    "id": "gpt-5-mini-medium",
    "handle": "openai/gpt-5-mini-2025-08-07",
    "label": "GPT-5-Mini (medium)",
    "description": "OpenAI's latest mini model (using their recommended reasoning level)",
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000
    }
  },
  {
    "id": "gpt-5-nano-medium",
    "handle": "openai/gpt-5-nano-2025-08-07",
    "label": "GPT-5-Nano (medium)",
    "description": "OpenAI's latest nano model (using their recommended reasoning level)",
    "updateArgs": {
      "reasoning_effort": "medium",
      "verbosity": "medium",
      "context_window": 272000
    }
  },
  {
    "id": "glm-4.6",
    "handle": "openrouter/z-ai/glm-4.6:exacto",
    "label": "GLM-4.6",
    "description": "The best open weights coding model",
    "updateArgs": {
      "context_window": 200000
    }
  },
  {
    "id": "minimax-m2",
    "handle": "openrouter/minimax/minimax-m2",
    "label": "Minimax M2",
    "description": "Minimax's latest model",
    "updateArgs": {
      "context_window": 196000
    }
  },
  {
    "id": "kimi-k2",
    "handle": "openrouter/moonshotai/kimi-k2-0905",
    "label": "Kimi K2",
    "description": "Kimi's latest model",
    "updateArgs": {
      "context_window": 262144
    }
  },
  {
    "id": "kimi-k2-thinking",
    "handle": "openrouter/moonshotai/kimi-k2-thinking",
    "label": "Kimi K2 Thinking",
    "description": "Kimi's K2 model with advanced thinking capabilities",
    "updateArgs": {
      "context_window": 256000,
      "max_output_tokens": 16000,
      "temperature": 1.0
    }
  },
  {
    "id": "deepseek-chat-v3.1",
    "handle": "openrouter/deepseek/deepseek-chat-v3.1",
    "label": "DeepSeek Chat V3.1",
    "description": "DeepSeek V3.1 model",
    "updateArgs": {
      "context_window": 128000
    }
  },
  {
    "id": "gemini-3",
    "handle": "google_ai/gemini-3-pro-preview",
    "label": "Gemini 3 Pro",
    "description": "Google's smartest model",
    "isFeatured": true,
    "updateArgs": { "context_window": 180000, "temperature": 1.0 }
  },
  {
    "id": "gemini-3-flash",
    "handle": "google_ai/gemini-3-flash-preview",
    "label": "Gemini 3 Flash",
    "description": "Google's fastest Gemini 3 model",
    "isFeatured": true,
    "updateArgs": { "context_window": 180000, "temperature": 1.0 }
  },
  {
    "id": "gemini-flash",
    "handle": "google_ai/gemini-2.5-flash",
    "label": "Gemini 2.5 Flash",
    "description": "Google's fastest model",
    "updateArgs": { "context_window": 180000 }
  },
  {
    "id": "gemini-pro",
    "handle": "google_ai/gemini-2.5-pro",
    "label": "Gemini 2.5 Pro",
    "description": "Google's last generation flagship model",
    "updateArgs": { "context_window": 180000 }
  },
  {
    "id": "gpt-4.1",
    "handle": "openai/gpt-4.1",
    "label": "GPT-4.1",
    "description": "OpenAI's most recent non-reasoner model",
    "updateArgs": { "context_window": 1047576 }
  },
  {
    "id": "gpt-4.1-mini",
    "handle": "openai/gpt-4.1-mini-2025-04-14",
    "label": "GPT-4.1-Mini",
    "description": "OpenAI's most recent non-reasoner model (mini version)",
    "updateArgs": { "context_window": 1047576 }
  },
  {
    "id": "gpt-4.1-nano",
    "handle": "openai/gpt-4.1-nano-2025-04-14",
    "label": "GPT-4.1-Nano",
    "description": "OpenAI's most recent non-reasoner model (nano version)",
    "updateArgs": { "context_window": 1047576 }
  },
  {
    "id": "o4-mini",
    "handle": "openai/o4-mini",
    "label": "o4-mini",
    "description": "OpenAI's latest o-series reasoning model",
    "updateArgs": { "context_window": 180000 }
  },
  {
    "id": "gemini-3-vertex",
    "handle": "google_vertex/gemini-3-pro-preview",
    "label": "Gemini 3 Pro (Vertex AI)",
    "description": "Google's smartest Gemini 3 Pro model on Vertex AI",
    "updateArgs": { "context_window": 180000, "temperature": 1.0 }
  }
]
